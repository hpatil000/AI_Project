**Overview**

This project showcases a Speech-to-Text recognition system implemented in Python using a Feedforward neural network. The system achieves an impressive 86% accuracy in transcribing .wav audio files. Leveraging advanced techniques such as MFCC feature extraction and dropout regularization, the model is optimized for robust performance.

**Key Features**

Feedforward Neural Network: The core of the system is a well-tailored Feedforward neural network that transforms audio input into accurate textual transcriptions.
Accuracy Achievement: Through meticulous training and validation, the system achieves an outstanding 86% accuracy, ensuring reliable and precise transcriptions.
MFCC Feature Extraction: Mel-frequency cepstral coefficients (MFCCs) are employed for feature extraction, capturing essential characteristics of the audio signal and enhancing the model's ability to discern patterns.
Dropout Regularization: Implementation of dropout regularization is instrumental in preventing overfitting, improving the model's generalization capabilities, and ensuring robust performance on diverse audio inputs.

**Usage**

To use the Speech-to-Text Recognition system, follow the instructions in the provided Python scripts. Ensure you have the required dependencies installed, which are listed in the accompanying requirements.txt file.

**Results**

The achieved 86% accuracy in transcribing .wav audio files underscores the effectiveness of the implemented neural network and optimization techniques.

**Future Work**

Feel free to contribute to this project by exploring additional optimization strategies, testing on diverse datasets, or integrating with other audio processing techniques.
